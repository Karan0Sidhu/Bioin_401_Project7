# -*- coding: utf-8 -*-
"""NER_TAGGING.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14KVsd4HiEZNEqdlgIG1Qlh4Y8ttz3cut
"""


import spacy

nlp = spacy.load("en_ner_bc5cdr_md")



import json

input_file = 'gpt_mixtral_instructions_train_tagged_NoOE.jsonl'



    #break # testing for 1
      # for line in tqdm(infile)

import json

# Assuming nlp and input_file are defined elsewhere
# Assuming nlp is a spaCy language model and input_file is the path to the input file

with open("gpt_mixtral_instructions_train_tagged_NoOE_karan.jsonl", 'w',encoding='utf-8') as outfile:
    with open(input_file, 'r',encoding='utf-8') as infile:
        for lin in infile:
            writer = {}
            line = json.loads(lin)
            text = line["input"]
            text_element = text
            doc = nlp(text)
            offset = 0
            for ent in doc.ents:
              #print(text_element[ent.start_char + offset - 1:ent.start_char + offset])
              if text_element[ent.start_char + offset - 1:ent.start_char + offset] != ">":
                  text_element = (text_element[:ent.start_char + offset] + f"<{ent.label_}>" +
                                  text_element[ent.start_char + offset:ent.end_char + offset] + f"</{ent.label_}>" +
                                  text_element[ent.end_char + offset:])
                  offset += (len(ent.label_) * 2) + 5

            writer["input"] = text_element
            writer["output"] = line["output"]

            # Convert dictionary to JSON string
            json_string = json.dumps(writer)

            # Write JSON string to file
            outfile.write(f'{json_string}\n')